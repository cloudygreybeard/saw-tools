# Analyzing Kubernetes API Usage with `oc adm must-gather` and `oc dev_tool audit`

## Overview

This guide walks Site Reliability Engineers (SREs) through auditing and analyzing Kubernetes (OpenShift) clusters using:

- `oc adm must-gather` with the `gather_audit_logs` script
- [`kubectl-dev_tool audit`](https://github.com/openshift/cluster-debug-tools)

This workflow helps identify high-volume API consumers, frequent `get` requests, or potentially suboptimal controller behaviour.

## Goals

- Extract and analyze Kubernetes API audit logs from a must-gather tarball
- Filter audit events for specific verbs and resources
- Support proactive investigations and RCA (root cause analysis)

---

## Step 1: Gather the Audit Logs

Run the following to collect audit logs from the cluster:

```bash
oc adm must-gather -- /usr/bin/gather_audit_logs
```

This will produce a folder similar to:

```
must-gather.local.*/audit_logs/kube-apiserver/
```

Each file corresponds to one API server node's logs.

> **Why audit logs?** Audit logs provide a timestamped, structured trail of all API requests received by the Kubernetes API server, enabling detailed investigation of what happened, when, and by whom.

---

## Step 2: Analyze Audit Logs with `kubectl-dev_tool`

Install [`kubectl-dev_tool`](https://github.com/openshift/cluster-debug-tools) if you haven't already. Then, run an analysis command like:

```bash
oc dev_tool audit -f 'audit_logs/kube-apiserver' \
  --verb=get \
  --resource='*.*' \
  --resource='-subjectaccessreviews.*' \
  --resource='-tokenreviews.*'
```

### Explanation

- `--verb=get`: Focus on high-volume `get` requests, which are often generated by controllers or overzealous watchers.
- `--resource='*.*'`: Match all resource types.
- `--resource='-subjectaccessreviews.*'` & `--resource='-tokenreviews.*'`: Exclude common noisy SAR and token review calls.

> **Why filter like this?** The goal is to highlight API usage patterns from workloads and controllers rather than authentication or RBAC-related queries.

---

## Step 3: Interpret the Results

The tool summarizes high-volume users, frequent requests, and possible overuse patterns. Look for:

- **Repeated calls from the same `userAgent`**: Might indicate a misbehaving operator or controller.
- **High frequency from a specific `namespace` or `serviceAccount`**: Could be an over-polling app.
- **Calls without RBAC errors but excessive frequency**: Opportunities for tuning.

---

## Bonus Tips

- Combine with Prometheus metrics (e.g., `apiserver_request_total`) to cross-check traffic volume.
- Use timestamps to correlate with incident timelines.
- Feed findings into tuning efforts: adjust controller resync periods, optimize watches, or consolidate frequent API calls.

---

## Cleanup

Audit logs can be large. After analysis, clean up temporary data:

```bash
rm -rf must-gather.local.*
```

---

## References

- [kubectl-dev_tool GitHub](https://github.com/openshift/cluster-debug-tools)
- [Must-gather documentation](https://docs.openshift.com/container-platform/latest/support/gathering-cluster-data.html)
- ["What is overloading my API?", from RedHatQuickCourses RH1 Lab 16 Module 4](https://github.com/RedHatQuickCourses/rh1-lab16-must-gather/blob/main/content/modules/ROOT/pages/module-04.adoc)
